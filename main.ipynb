{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44af9ff6-021c-40d0-b5d6-9f866c2f9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cell executed.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os, pandas as pd, numpy as np, pprint as pp, matplotlib.pyplot as plt, json\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "from clustering.clustering_funcs import cluster_glove\n",
    "from phonology.funcs import vectorize_phonology, find_phonology_cosine_similarity_perPhonType, stitch_parts\n",
    "from preprocess.funcs import remove_phonology_duplicate_videos, clear_phonology_df, clear_semantics_df\n",
    "from semantics.funcs import find_semantics_cosine_similarity_pairwise\n",
    "from utility.util_funcs import pandas_pair_signs_alphabetically\n",
    "from itertools import combinations\n",
    "\n",
    "from itertools import product\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c5b65-408b-4ed6-8fc4-84589e661e80",
   "metadata": {},
   "source": [
    "# 1. Data pre-processing\n",
    "\n",
    "In this part, we transform the datasets that we have to a format that allows comparisons:\n",
    "\n",
    "- We use pretrained English GloVe vectors (trained on the Wikipedia corpus) to extract semantic similarity between signs\n",
    "- For phonological similarity, we use annotated signs from the Gallaudet Dictionary for ASL, and the SignBank for BSL\n",
    "- The method that we follow does not allow a *direct* comparison between ASL and BSL. We use the available phonological annotations as the basis of our semantic space, which have different entries across the two languages; therefore, the semantic space, while they do share ~500 signs, are not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e06ac-a124-4b33-9ab3-df51ac9af743",
   "metadata": {},
   "source": [
    "## 1.1. Filtering the data\n",
    "\n",
    "In this section, we identify the ASL and the BSL signs that we will be working with.\n",
    "\n",
    "Each sign:\n",
    "- Has to have a phonological transcription\n",
    "- Has to have a semantic vector representation in the GloVe vectors\n",
    "- Must not have duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184a422-ed4f-4fd7-a8cb-e2b645d42c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonRoot_raw = \"data/raw/phonologyData/\"\n",
    "phon_paths_raw = [phonRoot_raw+p for p in os.listdir(phonRoot_raw) if (not p.startswith(\".\")) and (p.endswith(\"xlsx\"))]\n",
    "\n",
    "for p in phon_paths_raw:\n",
    "    print(p)\n",
    "    remove_phonology_duplicate_videos(p)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cd84f-bf32-4880-8736-a793af038684",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonRoot_unique = \"data/transforming/phonologyData/unique_signs/\"\n",
    "phon_paths_uniqueSigns = [phonRoot_unique+p for p in os.listdir(phonRoot_unique) if (not p.startswith(\".\")) and (p.endswith(\"gz\"))]\n",
    "\n",
    "gloveRoot = \"../../../Downloads/glove/\" #replace with path to Glove txt files\n",
    "glovePaths = [gloveRoot+g for g in os.listdir(gloveRoot) if not g.startswith(\".\")]\n",
    "\n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b49629-9e07-4431-a252-76bd35e8c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in phon_paths_uniqueSigns:\n",
    "    print(p)\n",
    "    clear_phonology_df(p)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95307d-6e70-4d2c-babf-371fed0bc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment below if you want to run - Takes about 5 minutes\n",
    "for (p, g) in product(phon_paths_uniqueSigns, glovePaths):\n",
    "    print(p, g)\n",
    "#     clear_semantics_df(p, g)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1bbeb-e313-4145-aa8d-2b484b304608",
   "metadata": {},
   "source": [
    "## 1.2. Transforming and Vectorizing the Phonology Data\n",
    "\n",
    "In this section, we transform the phonology dataframes of ASL and BSL with the following goals in mind:\n",
    "\n",
    "- All signs are lower-cased.\n",
    "- Duplicate signs are removed. Only the first occurrence of a sign is kept. This is a necessary step to avoid skewing the data. For instance, the BSL phonology dataframe has more than 10 entries for the sign MAUVE. We only keep the first occurrence of MAUVE in the order of the rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03361c01-e07f-4956-9e75-bb8e7185cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "phonRoot_clean = \"data/output/phonologyData/\"\n",
    "phonPaths_clean = [phonRoot_clean+p for p in os.listdir(phonRoot_clean) if not p.startswith(\".\")]\n",
    "\n",
    "#Uncomment below if you want to run - Takes about a couple minutes\n",
    "for p in phonPaths_clean:\n",
    "    print(p)\n",
    "    vectorize_phonology(p)\n",
    "\n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ec9e5-477b-47ed-84e2-bb5117d69853",
   "metadata": {},
   "source": [
    "## 2. Finding Phonological Similarity (Pairwise Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5400f89-4ef6-4b33-9661-0af79dccf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FINDING PHONOLOGICAL SIMILARITY FROM VECTORIZED DFs\"\"\"\n",
    "phonRoot_vectorized = \"data/output/vectorizedPhonDFs/\"\n",
    "phonPaths_vectorized = [phonRoot_vectorized+p for p in os.listdir(phonRoot_vectorized) if not p.startswith(\".\")]\n",
    "\n",
    "#Uncomment below if you want to run - Takes about over hour\n",
    "for p in phonPaths_vectorized:\n",
    "    print(p)\n",
    "#     find_phonology_cosine_similarity_perPhonType(p)\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8562db36-7067-4a7a-b292-bbe21d9606c0",
   "metadata": {},
   "source": [
    "## 3. Finding Semantic Similarity (Pairwise Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2384b4-cdaf-42e7-bf8f-e922004951a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "semPath_root = \"data/output/semanticsData/\"\n",
    "semPaths = [semPath_root+p for p in os.listdir(semPath_root) if not p.startswith(\".\")]\n",
    "\n",
    "#Uncomment below if you want to run - Takes over an hour\n",
    "for p in semPaths:\n",
    "    print(p)\n",
    "#     find_semantics_cosine_similarity_pairwise(p)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e6cf-85d9-4414-87de-c09cbebcfc91",
   "metadata": {},
   "source": [
    "## 4. Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3189d-0e49-425e-84bf-a1872d3065f3",
   "metadata": {},
   "source": [
    "## 4.1. Pairwise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39142d-2193-43db-8438-b20abf5ebdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"STITCHING TOGETHER PHONOLOGICAL SIMILARITY CSVs\"\"\"\n",
    "\n",
    "masterPath = \"data/output/vectorizedPhonDFs_Stitched_DFs/\"\n",
    "if not os.path.exists(masterPath):\n",
    "    os.makedirs(masterPath)\n",
    "    \n",
    "languages = [\"ASL\", \"BSL\"]\n",
    "phonTypes = [\"ENTIRE\", \"LOC\", \"MOV\", \"HS\"]\n",
    "\n",
    "#Uncomment below if you want to run - Takes about 5 minutes\n",
    "for language, phonType in product(languages, phonTypes):\n",
    "    print(language, phonType)\n",
    "    path = \"data/output/vectorized_PhonSim/\"+language+\"/\"+phonType+\"/\"\n",
    "#     df = stitch_parts(path)\n",
    "#     df.to_csv(masterPath+language+\"_\"+phonType+\".csv.gz\", compression=\"gzip\",index=False)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a2836-15b8-440f-bc2a-75e424ac47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"STITCHING TOGETHER SEMANTIC SIMILARITY CSVs\"\"\"\n",
    "\n",
    "masterPath = \"data/output/SemSim_StitchedDFs/\"\n",
    "if not os.path.exists(masterPath):\n",
    "    os.makedirs(masterPath)\n",
    "    \n",
    "languages = [\"ASL\", \"BSL\"]\n",
    "dims = [\"50d\", \"100d\", \"200d\", \"300d\"]\n",
    "\n",
    "#Uncomment below if you want to run - Takes about 5 minutes\n",
    "for language, dim in product(languages, dims):\n",
    "    print(language, dim)\n",
    "    path = \"data/output/SemSim/\"+language+\"/\"+dim+\"/\"\n",
    "#     df = stitch_parts(path)\n",
    "#     df.to_csv(masterPath+language+\"_\"+dim+\".csv.gz\", compression=\"gzip\",index=False)\n",
    "    \n",
    "print(\"\\n\\nCell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84fdb4-3df2-4fa9-b653-858e23795ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PAIRWISE CORRELATIONS ANALYSIS\"\"\"\n",
    "\n",
    "masterPhonPath = \"data/output/vectorizedPhonDFs_Stitched_DFs/\"\n",
    "masterSemPath = \"data/output/SemSim_StitchedDFs/\"\n",
    "semPaths = [masterSemPath + p for p in os.listdir(masterSemPath) if not p.startswith(\".\")]\n",
    "phonPaths = [masterPhonPath + p for p in os.listdir(masterPhonPath) if not p.startswith(\".\")]\n",
    "\n",
    "#Creating a dataframe to store pairwise calculations\n",
    "df_pairwise_calculations = pd.DataFrame(columns=[\"phonType\", \"semDimension\", \"language\", \"pearson_r\", \"p-value\"], index=range(32))\n",
    "\n",
    "\n",
    "df_Limit = None\n",
    "i = -1\n",
    "for s, p in list(product(semPaths, phonPaths))[:df_Limit]:\n",
    "    language_sem = s.split(\"/\")[-1].split(\"_\")[0]\n",
    "    language_phon = p.split(\"/\")[-1].split(\"_\")[0]\n",
    "    \n",
    "    if language_sem == language_phon:\n",
    "        i += 1\n",
    "        \n",
    "        language = language_sem\n",
    "        dim = s.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "        phonType = p.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]\n",
    "        \n",
    "        print(i, language, dim, phonType)\n",
    "        \n",
    "        df_pairwise_calculations.iloc[i][\"language\"] = language\n",
    "        df_pairwise_calculations.iloc[i][\"phonType\"] = phonType\n",
    "        df_pairwise_calculations.iloc[i][\"semDimension\"] = dim\n",
    "        \n",
    "        #Loading CSVs\n",
    "        phonDF = pd.read_csv(p)\n",
    "        semDF = pd.read_csv(s)\n",
    "        \n",
    "        phonDF[\"paired\"] = phonDF.apply(lambda x: pandas_pair_signs_alphabetically(x), axis=1)\n",
    "        semDF[\"paired\"] = semDF.apply(lambda x: pandas_pair_signs_alphabetically(x), axis=1)\n",
    "        \n",
    "        phonDF = phonDF.drop([\"s1\", \"s2\"], axis=1).set_index(\"paired\").sort_index()\n",
    "        semDF = semDF.drop([\"s1\", \"s2\"], axis=1).set_index(\"paired\").sort_index()\n",
    "        \n",
    "        \n",
    "        if all(phonDF.index == semDF.index):\n",
    "            print(\"All indices match.\\n\\n\")\n",
    "        else:\n",
    "            print(\"INDICES DO NOT MATCH.\\n\\n\")\n",
    "            \n",
    "        #Calculate correlations\n",
    "        df_pairwise_calculations.iloc[i][\"pearson_r\"], df_pairwise_calculations.iloc[i][\"p-value\"] = pearsonr(phonDF[phonType+\"_cosineSim\"], semDF[\"sem_cosineSim\"])\n",
    "        \n",
    "        \"\"\"ADD VISUALIZATIONS HERE\"\"\"\n",
    "        \n",
    "        del phonDF\n",
    "        del semDF\n",
    "        \n",
    "df_pairwise_calculations.to_csv(\"results/pairwise/pairwise_results.csv\", index=False)\n",
    "df_pairwise_calculations\n",
    "\n",
    "print(\"Cell executed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7c886d-88d2-4d90-a5f4-a72fe1ced2b4",
   "metadata": {},
   "source": [
    "### Results of the Pairwise Analysis:\n",
    "\n",
    "There is no apparent linear relationship between phonological similarity (as measured by the additive inverse of cosine distance between two signs in space that are vectorized) and semantic similarity (measured using the same cosine method as phonological similarity -- except we use GloVe vectors pretrained on the Wikipedia corpus).\n",
    "\n",
    "Phonology is arbitrary when the lexicon of an SL is taken as a whole.\n",
    "\n",
    "This brings us to our next analysis: Hierarchical Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec65882-d7b1-4a35-831a-44ebef30cae4",
   "metadata": {},
   "source": [
    "## 4.2. Hierarchical Clustering Analysis\n",
    "\n",
    "In this section, we raise the question that if there is no linear relationship in the phonology and semantics of pairs of signs in a semantically ***unorganized*** lexicon of an SL, can we find relationships betweeen pairs of signs within clusters of semantically related signs? \n",
    "\n",
    "1. We first cluster signs in a semantic vector space using agglomerative hierarchical clustering\n",
    "2. We then look for pairwise relations between pairs of signs within individual clusters.\n",
    "3. This dramatically reduces the number of sign pairs that we study, as the pairing process does not cross cluster boundaries in a given semantic vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0f0584b-dd89-427c-a4ca-a2079d5064ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLUSTERING -- pruning heights 0% through 100%'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/output/semanticsData/ASL_Semantics_50d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/ASL_Semantics_100d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/ASL_Semantics_200d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/ASL_Semantics_300d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/BSL_Semantics_50d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/BSL_Semantics_100d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/BSL_Semantics_200d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "data/output/semanticsData/BSL_Semantics_300d_clean.csv.gz\n",
      "0\n",
      "25\n",
      "50\n",
      "75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th>height</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ASL</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BSL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dim</th>\n",
       "      <th></th>\n",
       "      <th>50d</th>\n",
       "      <th>100d</th>\n",
       "      <th>200d</th>\n",
       "      <th>300d</th>\n",
       "      <th>50d</th>\n",
       "      <th>100d</th>\n",
       "      <th>200d</th>\n",
       "      <th>300d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1942</td>\n",
       "      <td>1943</td>\n",
       "      <td>1944</td>\n",
       "      <td>1945</td>\n",
       "      <td>1471</td>\n",
       "      <td>1476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1881</td>\n",
       "      <td>1934</td>\n",
       "      <td>1940</td>\n",
       "      <td>1941</td>\n",
       "      <td>1431</td>\n",
       "      <td>1461</td>\n",
       "      <td>1469</td>\n",
       "      <td>1472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1590</td>\n",
       "      <td>1858</td>\n",
       "      <td>1915</td>\n",
       "      <td>1932</td>\n",
       "      <td>1258</td>\n",
       "      <td>1415</td>\n",
       "      <td>1448</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>980</td>\n",
       "      <td>1568</td>\n",
       "      <td>1831</td>\n",
       "      <td>1875</td>\n",
       "      <td>821</td>\n",
       "      <td>1225</td>\n",
       "      <td>1402</td>\n",
       "      <td>1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>1009</td>\n",
       "      <td>1607</td>\n",
       "      <td>1746</td>\n",
       "      <td>486</td>\n",
       "      <td>846</td>\n",
       "      <td>1266</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>596</td>\n",
       "      <td>1175</td>\n",
       "      <td>1468</td>\n",
       "      <td>302</td>\n",
       "      <td>491</td>\n",
       "      <td>981</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>241</td>\n",
       "      <td>381</td>\n",
       "      <td>742</td>\n",
       "      <td>1017</td>\n",
       "      <td>211</td>\n",
       "      <td>297</td>\n",
       "      <td>620</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>171</td>\n",
       "      <td>259</td>\n",
       "      <td>479</td>\n",
       "      <td>647</td>\n",
       "      <td>142</td>\n",
       "      <td>199</td>\n",
       "      <td>389</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>310</td>\n",
       "      <td>413</td>\n",
       "      <td>106</td>\n",
       "      <td>144</td>\n",
       "      <td>253</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>107</td>\n",
       "      <td>128</td>\n",
       "      <td>212</td>\n",
       "      <td>274</td>\n",
       "      <td>79</td>\n",
       "      <td>109</td>\n",
       "      <td>174</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>105</td>\n",
       "      <td>156</td>\n",
       "      <td>196</td>\n",
       "      <td>63</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>122</td>\n",
       "      <td>144</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>99</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>112</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "language height   ASL                     BSL                  \n",
       "dim               50d  100d  200d  300d   50d  100d  200d  300d\n",
       "0             0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "1             1  1942  1943  1944  1945  1471  1476   NaN   NaN\n",
       "2             2  1881  1934  1940  1941  1431  1461  1469  1472\n",
       "3             3  1590  1858  1915  1932  1258  1415  1448  1462\n",
       "4             4   980  1568  1831  1875   821  1225  1402  1429\n",
       "5             5   580  1009  1607  1746   486   846  1266  1352\n",
       "6             6   361   596  1175  1468   302   491   981  1185\n",
       "7             7   241   381   742  1017   211   297   620   878\n",
       "8             8   171   259   479   647   142   199   389   547\n",
       "9             9   133   178   310   413   106   144   253   347\n",
       "10           10   107   128   212   274    79   109   174   221\n",
       "11           11    79   105   156   196    63    83   126   153\n",
       "12           12    61    79   122   144    54    64    99   114\n",
       "13           13    53    67   100   112    45    50    75    84\n",
       "14           14    45    56    71    88    41    41    58    68\n",
       "15           15    41    49    60    71    33    37    46    55\n",
       "16           16    34    40    49    55    30    31    39    42\n",
       "17           17    32    35    43    47    25    26    34    34\n",
       "18           18    26    31    36    40    23    23    27    30\n",
       "19           19    25    26    31    34    21    20    23    25\n",
       "20           20    22    23    28    30    19    17    21    22\n",
       "21           21    19    21    23    26    14    15    19    18\n",
       "22           22    18    19    21    22    13    14    15    16\n",
       "23           23    15    18    20    19    11    13    13    12\n",
       "24           24    12    16    18    17     9    10    11    11\n",
       "25           25    12    15    16    16     9     9    11    11\n",
       "26           26    11    13    14    14     9     8    10    10\n",
       "27           27    10    11    12    12     9     7     8     9\n",
       "28           28     8    10    10    11     8     7     8     8\n",
       "29           29     7     8     9    10     7     7     8     8\n",
       "30           30     7     8     8     8     6     7     8     7\n",
       "31           31     7     8     7     8     5     7     6     7\n",
       "32           32     6     6     7     7     4     6     6     6\n",
       "33           33     6     6     7     7     4     4     5     5\n",
       "34           34     6     6     7     7     4     4     5     4\n",
       "35           35     5     6     5     7     4     4     4     4\n",
       "36           36     5     5     5     6     3     4     4     4\n",
       "37           37     5     5     5     5     3     3     3     4\n",
       "38           38     5     3     5     4     3     3     3     4\n",
       "39           39     4     3     4     4     3     3     3     3\n",
       "40           40     3     3     3     4     3     3     3     3\n",
       "41           41     3     3     2     3     3     2     2     3\n",
       "42           42     2     3     2     3     2     2     2     2\n",
       "43           43     2     3     2     2     2     2     2     2\n",
       "44           44     2     3     2     2     2     2     2     2\n",
       "45           45     2     3     2     2     2     2     2     2\n",
       "46           46     2     3     2     2     2     2     2     2\n",
       "47           47     2     3     2     2     2     2     2     2\n",
       "48           48     2     3     2     2     2     2     2     2\n",
       "49           49     2     2     2     2     2     2     2     2\n",
       "50           50     2     2     2     2     2     2     2     2\n",
       "51           51     2     2     2     2     2     2     2     2\n",
       "52           52     2     2     2     2     2     2     2     2\n",
       "53           53     2     2     2     2     2     2     2     2\n",
       "54           54     2     2     2     2     2     2     2     2\n",
       "55           55     2     2     2     2     2     2     2     2\n",
       "56           56     2     2     2     2     2     2   NaN     2\n",
       "57           57     2     2     2     2     2     2   NaN     2\n",
       "58           58     2     2     2     2   NaN   NaN   NaN     2\n",
       "59           59     2     2     2     2   NaN   NaN   NaN     2\n",
       "60           60     2     2     2     2   NaN   NaN   NaN   NaN\n",
       "61           61     2     2     2     2   NaN   NaN   NaN   NaN\n",
       "62           62     2     2     2     2   NaN   NaN   NaN   NaN\n",
       "63           63     2     2     2     2   NaN   NaN   NaN   NaN\n",
       "64           64     2   NaN     2     2   NaN   NaN   NaN   NaN\n",
       "65           65     2   NaN     2     2   NaN   NaN   NaN   NaN\n",
       "66           66     2   NaN     2     2   NaN   NaN   NaN   NaN\n",
       "67           67     2   NaN     2   NaN   NaN   NaN   NaN   NaN\n",
       "68           68     2   NaN     2   NaN   NaN   NaN   NaN   NaN\n",
       "69           69     2   NaN     2   NaN   NaN   NaN   NaN   NaN\n",
       "70           70   NaN   NaN     2   NaN   NaN   NaN   NaN   NaN\n",
       "71           71   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "72           72   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "73           73   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "74           74   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "75           75   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "76           76   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "77           77   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "78           78   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "79           79   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "80           80   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "81           81   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "82           82   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "83           83   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "84           84   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "85           85   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "86           86   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "87           87   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "88           88   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "89           89   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "90           90   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "91           91   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "92           92   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "93           93   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "94           94   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "95           95   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "96           96   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "97           97   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "98           98   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
       "99           99   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed.\n"
     ]
    }
   ],
   "source": [
    "semPath_root = \"data/output/semanticsData/\"\n",
    "semPaths = [semPath_root+p for p in os.listdir(semPath_root) if not p.startswith(\".\")]\n",
    "\n",
    "languages = [\"ASL\", \"BSL\"]\n",
    "dims = [\"50d\", \"100d\", \"200d\", \"300d\"]\n",
    "\n",
    "heightRange = range(0,100)\n",
    "tuples = product(languages, dims)\n",
    "columns = pd.MultiIndex.from_tuples(tuples, names=[\"language\", \"dim\"])\n",
    "clusterN_df = pd.DataFrame(index=heightRange, columns=columns)\n",
    "\n",
    "\"\"\"CLUSTERING -- pruning heights 0% through 100%\"\"\"\n",
    "for language in languages:\n",
    "    for dim in dims:\n",
    "        masterPath = \"results/clustering/clusterIDs/\"+language+'/'+dim+'/'\n",
    "        \n",
    "        if not os.path.exists(masterPath):\n",
    "            os.makedirs(masterPath)\n",
    "\n",
    "        p = semPath_root+language+\"_Semantics_\"+dim+\"_clean.csv.gz\"\n",
    "        print(p)\n",
    "        \n",
    "        clusterLabels_dict = {}\n",
    "        for heit in heightRange:\n",
    "            \n",
    "            if heit%25 == 0:\n",
    "                print(heit)\n",
    "                \n",
    "            signs, silhouette, clusterLabels, clusters_len = cluster_glove(p, height=heit)\n",
    "            \n",
    "            if  1 < clusters_len < len(signs):\n",
    "                clusterN_df[(language, dim)].loc[heit] = clusters_len\n",
    "                temp_dict = {sign:cluster for sign, cluster in zip(signs, clusterLabels)}\n",
    "                height_key = \"height_\"+str(heit).zfill(3)\n",
    "                clusterLabels_dict[height_key] = {}\n",
    "                clusterLabels_dict[height_key][\"clusters\"] = {\"C\"+str(key).zfill(4): [value for value, check_key in temp_dict.items() if check_key==key] for key in temp_dict.values()}\n",
    "                clusterLabels_dict[height_key][\"silhouette_score\"] = silhouette\n",
    "                \n",
    "        with open(masterPath+language+\"_\"+dim+\"_\"+\"clusterIDs.json\", \"w\") as outfile:\n",
    "             json.dump(clusterLabels_dict, outfile)\n",
    "            \n",
    "\n",
    "clusterN_df = clusterN_df.reset_index()\n",
    "clusterN_df = clusterN_df.rename(columns={\"index\":\"height\"})\n",
    "clusterN_df.to_csv(\"results/clustering/clusterN_by_height.csv\", index=True)\n",
    "clusterN_df\n",
    "\n",
    "print(\"Cell executed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9138ca40-5b08-4c99-a4fd-e063471659ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/clustering/clusterIDs/ASL/50d/ASL_50d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/100d/ASL_100d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/200d/ASL_200d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/300d/ASL_300d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/50d/BSL_50d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/100d/BSL_100d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/200d/BSL_200d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/300d/BSL_300d_clusterIDs.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>dim</th>\n",
       "      <th>prune_height</th>\n",
       "      <th>cluster_N</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASL</td>\n",
       "      <td>50d</td>\n",
       "      <td>1</td>\n",
       "      <td>1942</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASL</td>\n",
       "      <td>50d</td>\n",
       "      <td>2</td>\n",
       "      <td>1881</td>\n",
       "      <td>0.014411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASL</td>\n",
       "      <td>50d</td>\n",
       "      <td>3</td>\n",
       "      <td>1590</td>\n",
       "      <td>0.0494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASL</td>\n",
       "      <td>50d</td>\n",
       "      <td>4</td>\n",
       "      <td>980</td>\n",
       "      <td>0.089183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASL</td>\n",
       "      <td>50d</td>\n",
       "      <td>5</td>\n",
       "      <td>580</td>\n",
       "      <td>0.088715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language  dim prune_height cluster_N silhouette_score\n",
       "0      ASL  50d            1      1942         0.002158\n",
       "1      ASL  50d            2      1881         0.014411\n",
       "2      ASL  50d            3      1590           0.0494\n",
       "3      ASL  50d            4       980         0.089183\n",
       "4      ASL  50d            5       580         0.088715"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell executed.\n"
     ]
    }
   ],
   "source": [
    "languages = [\"ASL\", \"BSL\"]\n",
    "dims = [\"50d\", \"100d\", \"200d\", \"300d\"]\n",
    "\n",
    "masterPath = \"results/clustering/clusterIDs/\"\n",
    "\n",
    "silhous = pd.DataFrame(columns = [\"language\", \"dim\", \"prune_height\", \"cluster_N\", \"silhouette_score\"], index=range(len(languages)*len(dims)*100))\n",
    "i = 0\n",
    "for language in languages:\n",
    "    for dim in dims:\n",
    "        read_json_path = masterPath+language+\"/\"+dim+\"/\"+language+\"_\"+dim+\"_clusterIDs.json\"\n",
    "        print(read_json_path)\n",
    "        with open(read_json_path, \"r\") as read_file:\n",
    "            clusterLabels = json.load(read_file)\n",
    "        \n",
    "        for heit in clusterLabels.keys():\n",
    "            height = int(heit.split(\"_\")[1])\n",
    "            silhous.iloc[i][\"language\"] = language\n",
    "            silhous.iloc[i][\"dim\"] = dim\n",
    "            silhous.iloc[i][\"prune_height\"] = height\n",
    "            silhous.iloc[i][\"cluster_N\"] = len(clusterLabels[heit][\"clusters\"])\n",
    "            silhous.iloc[i][\"silhouette_score\"] = clusterLabels[heit][\"silhouette_score\"]\n",
    "            i+= 1\n",
    "        \n",
    "    \n",
    "silhous = silhous.dropna()\n",
    "silhous.head()\n",
    "silhous.to_csv(\"results/clustering/clustering_silhouette_scores.csv\", index=False)\n",
    "\n",
    "print(\"Cell executed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72a2fe9f-aa3d-4e53-89b9-8f0343592df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  dim \n",
       "ASL       100d    0.081678\n",
       "          200d    0.065832\n",
       "          300d    0.058315\n",
       "          50d     0.089183\n",
       "BSL       100d    0.082187\n",
       "          200d    0.065350\n",
       "          300d    0.054349\n",
       "          50d     0.093459\n",
       "Name: silhouette_score, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhous.groupby([\"language\", \"dim\"])[\"silhouette_score\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5961c9ac-9427-44f4-9ba9-9488e8bf98ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/clustering/clusterIDs/ASL/50d/ASL_50d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/100d/ASL_100d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/200d/ASL_200d_clusterIDs.json\n",
      "results/clustering/clusterIDs/ASL/300d/ASL_300d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/50d/BSL_50d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/100d/BSL_100d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/200d/BSL_200d_clusterIDs.json\n",
      "results/clustering/clusterIDs/BSL/300d/BSL_300d_clusterIDs.json\n",
      "Cell executed.\n"
     ]
    }
   ],
   "source": [
    "languages = [\"ASL\", \"BSL\"]\n",
    "dims = [\"50d\", \"100d\", \"200d\", \"300d\"]\n",
    "\n",
    "masterPath = \"results/clustering/clusterIDs/\"\n",
    "\n",
    "for language in languages:\n",
    "    for dim in dims:\n",
    "        read_json_path = masterPath+language+\"/\"+dim+\"/\"+language+\"_\"+dim+\"_clusterIDs.json\"\n",
    "        print(read_json_path)\n",
    "        with open(read_json_path, \"r\") as read_file:\n",
    "            clusterLabels = json.load(read_file)\n",
    "            \n",
    "        masterOutPath = \"results/clustering/signPairs_byCluster/\"+language+\"/\"+dim+\"/\"\n",
    "        if not os.path.exists(masterOutPath):\n",
    "            os.makedirs(masterOutPath)\n",
    "        \n",
    "        for heit in clusterLabels.keys():\n",
    "            height = int(heit.split(\"_\")[1])\n",
    "            \n",
    "            height_condition = 2<height<11\n",
    "            #The range above is obtained from the silhouette scores.\n",
    "            #All VSMs have the max silhouette score between heights 4 and 7.\n",
    "            #So we only look at those VSMs where cluster validity is better:\n",
    "            \n",
    "            if height_condition:\n",
    "                signPairs = {cluster: [(x,y) for (x,y) in combinations(clusterLabels[heit][\"clusters\"][cluster],2)] for cluster in clusterLabels[heit][\"clusters\"] if len(clusterLabels[heit][\"clusters\"][cluster]) > 1}\n",
    "                out_json_path = masterOutPath+language+\"_\"+dim+\"_height\"+heit+\"_signPairs_byCluster.json\"\n",
    "                with open(out_json_path,'w') as outfile:\n",
    "                    json.dump(signPairs, outfile)\n",
    "            \n",
    "print(\"Cell executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216bc13-ea68-497b-b720-02ec35bad091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cf71d-d078-4d99-aa89-01c9261ce2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29364d53-06bd-4d6f-a6e9-7411353c0bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987ea75-dc66-477c-9684-342d01760206",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOutputPath = \"plots/heights_elbow/\"\n",
    "\n",
    "if not os.path.exists(plotOutputPath):\n",
    "    os.makedirs(plotOutputPath)\n",
    "    \n",
    "y_ticks = np.arange(0, 2000, 400)\n",
    "\n",
    "\n",
    "\n",
    "for p in semPaths[:limit]:\n",
    "    plt.figure(figsize=(12,12))\n",
    "    print(p, \"\\n\")\n",
    "    \n",
    "    language = p.split(\"/\")[-1].split(\"_\")[0]\n",
    "    dim = p.split(\"/\")[-1].split(\"_\")[2]\n",
    "    \n",
    "    heights = []\n",
    "    for heit in range(100):\n",
    "        clusters = cluster_glove(p, height=heit)\n",
    "        clustersN = len(list(set([x[0] for x in clusters])))\n",
    "        heights += [(heit, clustersN)]\n",
    "        \n",
    "    plt.scatter([x[0] for x in heights], [x[1] for x in heights])\n",
    "    _=plt.yticks(y_ticks)\n",
    "    _=plt.axes().set_ylim(-100, 2000)\n",
    "    _=plt.axes().set_xlim(-5,100)\n",
    "    plt.savefig(plotOutputPath+language+\"_\"+dim+\".png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505185f-e1f0-4fd2-b8ef-293d89e69b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f565-d43f-4134-af08-e802643cbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd, numpy as np, os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from scipy.cluster.hierarchy import dendrogram\n",
    "# from scipy.cluster import hierarchy\n",
    "\n",
    "# distance_Tresholds = [\n",
    "#     6,\n",
    "# #                         7,\n",
    "# #                       8,9,10,\n",
    "# #                       11, 12,\n",
    "#     13, 14, 15\n",
    "    \n",
    "#                      ]\n",
    "\n",
    "# inputPath = semPaths\n",
    "# outputPath = \"../../04.Analyses/hierarchicalClustering/gloVe_VSMs_ClusteredHierarchical/\"\n",
    "# gloves = [x for x in os.listdir(inputPath) if not x.startswith(\".\")]\n",
    "\n",
    "# method = \"ward\"\n",
    "# distanceMethod = \"euclidean\"\n",
    "\n",
    "# Limit = None\n",
    "# for glove in gloves[:Limit]:\n",
    "#     datasetName = glove\n",
    "#     print(\"Now working on \", glove)\n",
    "#     data = pd.read_csv(inputPath+datasetName).set_index(\"label\")[:]\n",
    "#     print(\"length of data:\", len(data))\n",
    "#     data.head()\n",
    "#     dataOutput = data.reset_index()\n",
    "#     X = data\n",
    "#     signs = [x for x in data.index]\n",
    "#     # print(signs)\n",
    "\n",
    "#     for threshold in distance_Tresholds:\n",
    "#         model = AgglomerativeClustering(linkage= method,\n",
    "#                                         affinity= distanceMethod,\n",
    "#                                         distance_threshold=threshold,\n",
    "#                                         n_clusters=None,\n",
    "#                                         compute_distances=True\n",
    "#                                        )\n",
    "#         model_fit = model.fit(X)\n",
    "#         clusters = [\"C\"+str(c) for c in list(model.fit_predict(X))]\n",
    "#         dataOutput[\"clusters\"] = clusters\n",
    "# #             dataOutput[\"labels\"] = signs\n",
    "\n",
    "#         dataOutput.to_csv(outputPath+glove[:-4]+\"_height\"+str(threshold)+\".csv\", index=False)\n",
    "\n",
    "\n",
    "#         print(\"N of clusters: \", model_fit.n_clusters_)\n",
    "\n",
    "\n",
    "# print(\"this cell executed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
